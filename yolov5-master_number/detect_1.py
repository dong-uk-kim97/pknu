# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
"""
Run YOLOv5 detection inference on images, videos, directories, globs, YouTube, webcam, streams, etc.

Usage - sources: # weightsëŠ” ì§ì ‘ í•™ìŠµëœ ëª¨ë¸ ë˜ëŠ” yoloê°€ ê¸°ë³¸ìœ¼ë¡œ ì œê³µí•´ì£¼ëŠ” ëª¨ë¸ì˜ ì¢…ë¥˜, sourceëŠ” ì–´ë–¤ ì¡°ë¥˜ì˜ ì¸ì‹ì„ ì‚¬ìš©í•  ê²ƒì¸ì§€ ì •í•¨
    $ python detect.py --weights yolov5s.pt --source 0                               # webcam
                                                     img.jpg                         # image
                                                     vid.mp4                         # video
                                                     screen                          # screenshot
                                                     path/                           # directory
                                                     list.txt                        # list of images
                                                     list.streams                    # list of streams
                                                     'path/*.jpg'                    # glob
                                                     'https://youtu.be/LNwODJXcvt4'  # YouTube
                                                     'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream //ì¹´ë©”ë¼ ì˜ìƒì„ ì ‘ì†í•´ì„œ ì¸ì‹í•˜ê¸° ìœ„í•œ êµ¬ë¬¸
sourceë³„ ì´ë¯¸ì§€, ë™ì˜ìƒ, RTSP ë“±ì„ ì„ íƒí•´ì„œ ì‚¬ìš©

ëª¨ë¸ì„ ì„ ì • ëª¨ë¸ì— ë§ê²Œ ì†ë„ë¥¼ ë¹ ë¥´ê²Œ í•˜ê³  ì‹¶ìœ¼ë©´ ì¸ì‹ë¥ ì€ ì¡°ê¸ˆ ë‚®ì•„ë„ yolov5s ì†ë„ëŠ” ëŠë ¤ë„ ì¸ì‹ë¥ ì„ ë†’ì´ê³  ì‹¶ìœ¼ë©´ yolov5x
Usage - formats:
    $ python detect.py --weights yolov5s.pt                 # PyTorch
                                 yolov5s.torchscript        # TorchScript
                                 yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                 yolov5s_openvino_model     # OpenVINO
                                 yolov5s.engine             # TensorRT
                                 yolov5s.mlmodel            # CoreML (macOS-only)
                                 yolov5s_saved_model        # TensorFlow SavedModel
                                 yolov5s.pb                 # TensorFlow GraphDef
                                 yolov5s.tflite             # TensorFlow Lite
                                 yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                                 yolov5s_paddle_model       # PaddlePaddle
ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ ë° ë”¥ëŸ¬ë‹ì€ Tensorflow, kerasë¥¼ ì‚¬ìš©í•˜ì˜€ìœ¼ë‚˜ Yolov5ë¶€í„°ëŠ” PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ìµœëŒ€í™”ë¡œ ì˜¬ë¦¼ 
"""

import argparse # cmd ë™ì‘ì„ ì‹œí‚¤ê¸° ìœ„í•œ í´ë˜ìŠ¤(epoch, batch_size, ir_initial)
import csv
import os
import platform
import sys
from pathlib import Path

import torch # PyTorch ë¶ˆëŸ¬ì˜´
# facebookì—ì„œ ì œê³µí•˜ëŠ” ë”¥ëŸ¬ë‹ ë„êµ¬ë¡œì„œ, numpyì™€ íš¨ìœ¨ì ì¸ ì—°ë™ì„ ì§€ì›í•˜ëŠ” í¸ë¦¬í•œ ë„êµ¬ì´ë‹¤.
# êµ¬ê¸€ì—ì„œëŠ” tensorflowì—ì„œ ê°œë°œ
# tensorflowë‚˜ pytorchë‚˜ ê¸°ë³¸ì ì¸ data structureì€ tensorì´ë‹¤.
# tensorë€ 2ì°¨ì› ì´ìƒì˜ arrayì´ë©°, matrix, vectorì˜ ì¼ë°˜í™”ëœ ê°ì²´ì´ë‹¤.

# ì¼ë°˜í™”ëœ ì •ì˜ : 
# vectorëŠ” 1ì°¨ì› tensorì´ë‹¤.
# matrixëŠ” 2ì°¨ì› tensorì´ë‹¤.
# ìƒ‰ì„ ë‚˜íƒ€ë‚´ëŠ” RGBëŠ” 3ì°¨ì› tensorì´ë‹¤.

# í•™ìŠµ ë° ì¸ì‹ì—ëŠ” ë‘ ê°€ì§€ ë°©ë²•ì´ ìˆëŠ”ë° CPUì‚¬ìš©ê³¼ GPU(CUDA)ì‚¬ìš©ìœ¼ë¡œ ì•ì˜ ì†ŒìŠ¤ì½”ë“œëŠ” GPUê°€ ìˆë‹¤ë©´ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš©í•˜ê² ë‹¤ê³  ì„ ì–¸
import torch.backends.cudnn as cudnn
global_list_num = None

FILE = Path(__file__).resolve() # í˜„ì¬ .pyì˜ ê²½ë¡œë¥¼ ë¶ˆëŸ¬ì™€ì„œ FILEì— ëŒ€ì…
ROOT = FILE.parents[0]  # YOLOv5 root directory 
if str(ROOT) not in sys.path: # ë§Œì•½ ROOTê°€ ì—†ë‹¤ë©´ 
    sys.path.append(str(ROOT))  # add ROOT to PATH í•œë²ˆ ë” ì‹œë„ sys.pathì— í˜„ì¬ í´ë”ë¥¼ ì¶”ê°€í•˜ì—¬ importê°€ ê°€ëŠ¥í•´ì§
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative ROOTë¥¼ ì°¾ì•˜ë‹¤ë©´ ê²½ë¡œì™€ cwdë¥¼ ROOTì— ëŒ€ì… relative ROOTì™€ í„°ë¯¸ë„ í˜„ì¬ ìœ„ì¹˜ì™€ì˜ ìƒëŒ€ê²½ë¡œ 

expe = 0
expe_f = 0
check_image =""
sellect = 0

# YOLOë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì„ ì–¸ìœ¼ë¡œ YOLO ê´€ë ¨ ì‚¬ìš©ì„ ì„ ì–¸í•œ êµ¬ë¬¸ 
from ultralytics.utils.plotting import Annotator, colors, save_one_box

from models.common import DetectMultiBackend
from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams
from utils.general import (
    LOGGER,
    Profile,
    check_file,
    check_img_size,
    check_imshow,
    check_requirements,
    colorstr,
    cv2,
    increment_path,
    non_max_suppression,
    print_args,
    scale_boxes,
    strip_optimizer,
    xyxy2xywh,
)
from utils.torch_utils import select_device, smart_inference_mode
# from PIL import Image # opencvë¡œ ì´ë¯¸ì§€ ë˜ëŠ” ì˜ìƒì„ imshow()í•  ìˆ˜ ìˆê³ , ì•„ë‹ˆë©´ PILë¡œ ì´ë¯¸ì§€ ë˜ëŠ” ì˜ìƒì„ showí•  ìˆ˜ ìˆë‹¤.

@smart_inference_mode()
def run(
    weights=ROOT / "best.pt",  # model path or triton URL
    source=ROOT / "../car_plate/image3/val/images",  # file/dir/URL/glob/screen/0(webcam) ì¸ì‹ ì‹œí‚¬ í´ë” ê²½ë¡œ
    data=ROOT / "data/coco128.yaml",  # dataset.yaml path í´ë˜ìŠ¤ê°€ ì •ì˜ ë˜ì–´ ìˆëŠ” íŒŒì¼ 
    # imgsz=(640, 640),  # inference size (height, width)
    imgsz=(416, 416),  # inference size (height, width)
    conf_thres=0.25,  # confidence threshold
    iou_thres=0.45,  # NMS IOU threshold
    max_det=1000,  # maximum detections per image
    device="",  # cuda device, i.e. 0 or 0,1,2,3 or cpu
    view_img=False,  # show results
    save_txt=False,  # save results to *.txt
    save_csv=False,  # save results in CSV format
    save_conf=False,  # save confidences in --save-txt labels
    save_crop=False,  # save cropped prediction boxes
    nosave=False,  # do not save images/videos
    classes=None,  # filter by class: --class 0, or --class 0 2 3
    agnostic_nms=False,  # class-agnostic NMS
    augment=False,  # augmented inference
    visualize=False,  # visualize features
    update=False,  # update all models
    project=ROOT / "",  # save results to project/name
    name="",  # save results to project/name
    exist_ok=False,  # existing project/name ok, do not increment existëŠ” ì›í•˜ëŠ” í´ë”ì— íŒŒì¼ì´ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ ì•Œê¸° ìœ„í•œ êµ¬ë¬¸ 
    line_thickness=1,  # bounding box thickness (pixels) ë°•ìŠ¤ êµµê¸°
    hide_labels=False,  # hide labels
    hide_conf=False,  # hide confidences
    half=False,  # use FP16 half-precision inference
    dnn=False,  # use OpenCV DNN for ONNX inference
    vid_stride=1,  # video frame-rate stride
):
    global expe, check_image, sellect, expe_f
    source = str(source) # ì¸ì‹ì„ ì‹œí‚¬ ì´ë¯¸ì§€ë“¤ì´ ë‹´ê²¨ ìˆëŠ” ê²½ë¡œ
    check_image = None # check_imageì— Noneê°’ì„ ëŒ€ì… ì¦‰ ì´ˆê¸°í™”
    save_img = not nosave and not source.endswith(".txt")  # save inference images í™•ì¥ìë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•œ êµ¬ë¬¸ save inference images notì˜ ì˜ë¯¸ ë’¤ì— ì˜¤ëŠ” ì¡°ê±´ë¬¸ì´ ê±°ì§“ì´ë©´ ì¡°ê±´ì„ ë§Œì¡±
    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS) # IMG_FORMATS + VID_FORMATSê°’ì„ is_fileì˜ ì²˜ìŒë¶€í„° íŒŒì¼ì´ ìˆëŠ” ëê¹Œì§€ ì½ì–´ì™€ì„œ is_fileì— ëŒ€ì… 
    # .suffixëŠ” ê²½ë¡œì— ì§€ì •ëœ íŒŒì¼ì˜ íŒŒì¼ í™•ì¥ì(ì  í¬í•¨)ë¥¼ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ
    # [1:] ë‘ë²ˆì§¸ ìœ„ì¹˜ ì´í›„ì˜ ëª¨ë“  ë¬¸ì(ì¦‰ ì ì œì™¸)ë¥¼ ì¶”ì¶œí•˜ëŠ” ìŠ¬ë¼ì´ìŠ¤ ì‘ì—…
    # íŒŒì¼ í™•ì¥ìê°€ ì´ë¯¸ì§€í˜•ì‹(.jpg, .png)ë“±ì— í•´ë‹¹í•˜ëŠ” ê²½ìš° í‘œí˜„ì‹ì€ True
    # íŒŒì¼ í™•ì¥ìê°€ ë¹„ë””ì˜¤í˜•ì‹(.mp4, .avi)ë“±ì— í•´ë‹¹í•˜ëŠ” ê²½ìš° í‘œí˜„ì‹ì€ True
    # ì¦‰ í™•ì¥ìì— ë”°ë¼ì„œ ì´ë¯¸ì§€ì¸ì§€ ë¹„ë””ì˜¤ì¸ì§€ë¥¼ íŒë³„í•˜ê¸° ìœ„í•œ êµ¬ë¬¸ 
    is_url = source.lower().startswith(("rtsp://", "rtmp://", "http://", "https://")) # í†µì‹  ê²½ë¡œë¥¼ ì„ íƒ 
    # .lower()ì€ ëª¨ë“  ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ëŠ” ë©”ì„œë“œ
    # .startswith()ì€ ë¬¸ìì—´ì´ ì§€ì •ëœ ì ‘ë‘ì‚¬ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸ 
     
    webcam = source.isnumeric() or source.endswith(".streams") or (is_url and not is_file) # ì›¹ìº ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ êµ¬ë¬¸
    # .isnumeric()ì€ ë¬¸ìì—´ì˜ ëª¨ë“  ë¬¸ìê°€ ìˆ«ìì´ë©´ True, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Falseë¥¼ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ
    
    screenshot = source.lower().startswith("screen")
    if is_url and is_file:
        source = check_file(source)  # download

    # Directories
    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run íŒŒì¼ì´ ìˆë‹¤ë©´ runí´ë”/detectí´ë”/exp íŒŒì¼ì´ë¦„ì´ ë™ì¼í•œ íŒŒì¼ì´ ìˆìœ¼ë©´ ë’¤ì— 2,3,4 ë“±ì„ ë¶™ì—¬ì¤€ë‹¤
    (save_dir / "labels" if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir ë””ë ‰í† ë¦¬ê°€ ì—†ë‹¤ë©´ ë§Œë“¤ì–´ë¼ 

    # Load model
    device = select_device(device) # CPU, GPU ì„ íƒ 
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half) # weights= ë§Œì•½ ë¼ë²¨ë§í•˜ê³  í•™ìŠµì„ ë§ˆì¹˜ë©´ best.pt
    stride, names, pt = model.stride, model.names, model.pt
    # strideëŠ” íŒŒë¼ë¯¸í„°(convolution í•„í„°ê°€ ì´ë™í•˜ëŠ” ë‹¨ê³„ í¬ê¸°ë¥¼ ê²°ì •)
    # strideê°€ í¬ë©´ í•œë²ˆì— ë§ì€ í”½ì…€ì„ ì´ë™í•˜ë¯€ë¡œ ì¶œë ¥ì´ ë‹¤ìš´ìƒ˜í”Œë§ ëœë‹¤.
    # strideê°€ ì‘ìœ¼ë©´ í•œë²ˆì— ë§ì€ í”½ì…€ì„ ì´ë™í•  ìˆ˜ ì—†ê³  ì‘ì€ í”½ì…€ì„ ì´ë™í•˜ë¯€ë¡œ ì¶œë ¥ í•´ìƒë„ê°€ ì˜¬ë¼ê°
    # ì‹¤ì œë¡œ strideê°’ì€ ì•„í‚¤í…ì²˜ì™€ íŠ¹ì • ì‘ì—…ì— ë”°ë¼ ì„¤ì •ë˜ëŠ” ê²½ìš°ê°€ ìˆìŒ 
    # model.namesëŠ” ê°ì²´ íƒì§€ ë˜ëŠ” ë¶„ë¥˜ ëª¨ë¸ê³¼ ê´€ë ¨ëœ í´ë˜ìŠ¤ ì´ë¦„ ë˜ëŠ” ë ˆì´ë¸” ëª©ë¡ì„ ì°¸ì¡°
    # ì‚¬ì „ í›ˆë ¨ëœ ë§ì€ ëª¨ë¸ì—ì„œ model.namesì—ëŠ” (ex. "ê°œ", "ìë™ì°¨", "íŠ¸ëŸ­", "ë²„ìŠ¤")ë“±ë“± ì¼ë°˜ì ì¸ ê°œì²´ ë²”ì£¼ì— ëª©ë¡ì´ í¬í•¨ë˜ì–´ ìˆë‹¤.
    # model.ptëŠ” Pytorchëª¨ë¸ì— ë¡œë“œí•˜ë©´ ì €ì¥ëœ ê°€ì¤‘ì¹˜ë¡œ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì–´ ì¶”ë¡ ì´ë‚œ ì¶”ê°€ êµìœ¡ì— ì‚¬ìš©
    # ì—¬ê¸°ì—ëŠ” í•™ìŠµëœ ì‹ ê²½ë§ì˜ í•™ìŠµëœ ê°€ì¤‘ì¹˜ì™€ ì•„í‚¤í…ì²˜ê°€ í¬í•¨ 
    
    imgsz = check_img_size(imgsz, s=stride)  # check image size ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ 
    
    # imgszì˜ ê²½ìš° ë§¤ê°œë³€ìˆ˜ ì²˜ë¦¬ì— í•„ìš”í•œ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ì¦‰ ë„ˆë¹„ì™€ ë†’ì´ë¥¼ í¬í•¨í•˜ëŠ” ë‹¨ì¼ ê°’(ì •ì‚¬ê°í˜• ì´ë¯¸ì§€)ì´ê±°ë‚˜ íŠœí”Œ(ì§ì‚¬ê°í˜• ì´ë¯¸ì§€)ë¥¼ ë‚˜íƒ€ë‚  ë•Œ ì‚¬ìš©
    # s = stride ë§¤ê°œë³€ìˆ˜ëŠ” ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ë•Œ ë‹¨ê³„ í¬ê¸°ë¥¼ ì§€ì •. ì²˜ë¦¬ì°½(ex ì»¨ë³¼ë£¨ì…˜ í•„í„°)
    # ì´ë¯¸ì§€ì—ì„œ ìˆ˜í‰ ë° ìˆ˜ì§ìœ¼ë¡œ ì´ë™í•˜ëŠ” ì •ë„ë¥¼ ê²°ì • ìœ„ ë‚´ìš©ì„ ë‹¤ì‹œ ë³´ë©´ ìŠ¤íŠ¸ë¼ì´ë“œê°€ í¬ë©´ ë‹¤ìš´ìƒ˜í”Œë§ ì‘ìœ¼ë©´ ë¯¸ì„¸í•œ ì„¸ë¶€ì •ë³´ê°€ ìœ ì§€(ë‹¨ ì²˜ë¦¬ì†ë„ê°€ í˜„ì €íˆ ë–¨ì–´ì§)
    
    # Dataloader
    bs = 1  # batch_size
    if webcam:
        view_img = check_imshow(warn=True)
        cudnn.benchmark = True # constant image size inference ê·¸ë˜í”½ì¹´ë“œ Cuda Coreë¥¼ í™œì„±í™” 
        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)
        bs = len(dataset)
    elif screenshot:
        dataset = LoadScreenshots(source, img_size=imgsz, stride=stride, auto=pt)
    else:
        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)
        # LoadImages í•¨ìˆ˜ëŠ” ì§€ì •ëœ ì†ŒìŠ¤(ë””ë ‰í„°ë¦¬ ë˜ëŠ” íŒŒì¼ ê²½ë¡œ)ì—ì„œ ì´ë¯¸ì§€ ì„¸íŠ¸ë¥¼ ë¡œë“œ
        # ë¹„ì „ ì‘ì—…ì—ì„œëŠ” í›ˆë ¨, ê²€ì¦ ë˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ì—¬ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì 
        # auto=ptëŠ” ë§¤ê°œë³€ìˆ˜ í•¨ìˆ˜ê°€ Pytorch í˜¸í™˜ ë°ì´í„° ë¡œë“œ(ex ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜)ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬
        
    vid_path, vid_writer = [None] * bs, [None] * bs
    # vid_path, vid_writerì„ ì´ˆê¸°í™” ì²˜ë¦¬
    # vid_pathëŠ” [None] * bs bsëŠ” ë°°ì¹˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ëƒ„
    # vid_writer ìœ„ì™€ ë™ì¼
    # ë¹„ë””ì˜¤ë¥¼ ì¼ê´„ ì²˜ë¦¬í•  ë•Œ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì¶”ì í•˜ê¸° ìœ„í•´ ì‚¬ìš© 

# Run inference
    model.warmup(imgsz=(1 if pt or model.triton else bs, 3, *imgsz))  # warmup
    # ì‚¬ì „ ì •ì˜ëœ ì‹ ê²½ë§ ëª¨ë¸ì„ ì˜ë¯¸
    # .warmup()ì˜ ê²½ìš° ì´ˆê¸°í™”ë¥¼ ì§„í–‰
    # imgszì˜ ê²½ìš° ëª¨ë¸ì˜ ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì§€ì •, ë„ˆë¹„ì™€ ë†’ì´ë¥¼ í¬í•¨í•˜ëŠ” ë‹¨ì¼ ê°’(ì •ì‚¬ê°í˜•ì˜ ì´ë¯¸ì§€)ì´ê±°ë‚˜ íŠœí”Œ(ì§ì‚¬ê°í˜•ì˜ ì´ë¯¸ì§€)
    # (1 if pt or model.triton else bs, 3, *imgsz) ì„¸ ê°€ì§€ ìš”ì†Œë¡œ íŠœí”Œ êµ¬ì„± 
    # ì²« ë²ˆì§¸ ìš”ì†Œ 1ì€ ë°°ì¹˜ í¬ê¸° 
    # ë‘ ë²ˆì¨° ìš”ì†Œ 3ì€ ìƒ‰ìƒ ì±„ë„ì˜ ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ„
    # ì„¸ ë²ˆì§¸ ìš”ì†Œ imgsz(ë„ˆë¹„ì™€ ë†’ì´)
    # ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™”í•˜ê±°ë‚˜ í•™ìŠµ ì†ë„ë¥¼ ì¡°ì •í•˜ê±°ë‚˜ í›ˆë ¨ ì „ì— ê¸°íƒ€ í•„ìš”í•œ ì„¤ì •ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•¨
    # í”„ë ˆì„ì›Œí¬(ex Pytorch, Tensorflow)ì— ë”°ë¼ ê°’ì´ ë‹¬ë¼ì§
    
    # ë³€ìˆ˜ ë° ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    seen, windows, dt = 0, [], (Profile(device=device), Profile(device=device), Profile(device=device))
    # seen ë³€ìˆ˜ë¥¼ int 0ìœ¼ë¡œ ì´ˆê¸°í™”
    # windows ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™” 
    # dt íŠœí”Œì„ (Profile í•¨ìˆ˜ì— ë§ê²Œ ì´ˆê¸°í™”)
    
    for path, im, im0s, vid_cap, s in dataset: 
        # pathëŠ” ì´ë¯¸ì§€ íŒŒì¼ì´ë‚˜ ë¹„ë””ì˜¤ì˜ ê²½ë¡œ
        # imì€ ë¡œë“œëœ ì´ë¯¸ì§€(tensor)
        # im0s ì „ì²˜ë¦¬ê°€ ëœ ì´ë¯¸ì§€ 
        # vid_capì˜ ê²½ìš° ë¹„ë””ì˜¤ì¸ì§€ ì•„ë‹Œì§€ êµ¬ë¶„í•˜ê¸° ìœ„í•¨
        # sëŠ” datasetê³¼ ê´€ë ¨ëœ ì¶”ê°€ì •ë³´(ex ë¼ë²¨, ë©”íƒ€ë°ì´í„°)
        # ê°ì²´ê°ì§€, ë¶„í•  ë˜ëŠ” ë¶„ë¥˜ë¥¼ ìœ„í•´ ë°˜ë³µë¬¸ì„ ì‹¤í–‰ 
        
        with dt[0]:  # ì´ë¯¸ì§€ ë³€í™˜ ì •ê·œí™”
            im = torch.from_numpy(im).to(model.device) # ì´ë¯¸ì§€ ë°ì´í„°ëŠ” Pytorch í…ì„œ(im)ë¡œ ë³€í™˜ë˜ì–´ ì§€ì •ëœ GPU ë˜ëŠ” CPUë¡œ ì´ë™
            im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32 / ëª¨ë¸ì´ fp16ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì´ë¯¸ì§€ëŠ” fp16í˜•ì‹ìœ¼ë¡œ ì¶”ê°€ ë³€í™˜ 
            im /= 255  # 0 - 255 to 0.0 - 1.0 / í”½ì…€ ê°’ì€ [0,255]ì—ì„œ [0.0, 1.0]ë²”ìœ„ë¡œ ì •ê·œí™” 
            if len(im.shape) == 3:
                im = im[None]  # expand for batch dim
            if model.xml and im.shape[0] > 1:
                ims = torch.chunk(im, im.shape[0], 0)

        # Inference
        with dt[1]:
            visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False 
            if model.xml and im.shape[0] > 1:
                pred = None
                for image in ims:
                    if pred is None:
                        pred = model(image, augment=augment, visualize=visualize).unsqueeze(0)
                    else:
                        pred = torch.cat((pred, model(image, augment=augment, visualize=visualize).unsqueeze(0)), dim=0)
                pred = [pred, None]
            else:
                pred = model(im, augment=augment, visualize=visualize) # yolo ëª¨ë¸ì— í˜„ì¬ ì´ë¯¸ì§€ ë˜ëŠ” ì˜ìƒì„ ëŒ€ì… 
        # NMS ì¤‘ë³µ íƒì§€ë¥¼ í•„í„°ë§í•˜ê¸° ìœ„í•´ ì ìš©
        with dt[2]:
            pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det) # ì‹ ë¢°ê°’, IoU ì„ê³„ê°’, í´ë˜ìŠ¤ í•„í„°ë§ê³¼ ê°™ì€ ë§¤ê°œë³€ìˆ˜ ì ìš© 
            # ìµœì¢… íƒì§€ëŠ” predì— ì €ì¥

    # Second-stage classifier (optional)
    # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)

    # Define the path for the CSV file
    csv_path = save_dir / "predictions.csv"

    # Create or append to the CSV file
    def write_to_csv(image_name, prediction, confidence):
        """Writes prediction data for an image to a CSV file, appending if the file exists."""
        data = {"Image Name": image_name, "Prediction": prediction, "Confidence": confidence}
        with open(csv_path, mode="a", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=data.keys())
            if not csv_path.is_file():
                writer.writeheader()
            writer.writerow(data)

        # Process predictions ê°ì²´ íƒì§€ í”„ë¡œì„¸ìŠ¤ 
        for i, det in enumerate(pred):  # per image ì—¬ê¸°ì„œ ë¶€í„° ì‹¤ì œ ì¸ì‹ ê³„ì‚°ì´ ì‹¤í–‰ë¨ 
            # ë°˜ë³µí•˜ëŠ” ë™ì•ˆ í•´ë‹¹ ì¸ë±ìŠ¤ë¥¼ ì¶”ì (ì¸ë±ìŠ¤-ê°’) ì—´ê±° ê°ì²´ë¥¼ ë°˜í™˜
            
            seen += 1 # seenì´ë¼ëŠ” ë³€ìˆ˜ë¥¼ ìš°ì„  1ë¡œ ì¦ê°€ì‹œí‚´ 
            if webcam:  # batch_size >= 1
                p, im0, frame = path[i], im0s[i].copy(), dataset.count # pì— path[i]ë¥¼ ëŒ€ì…, im0ì— im0s.copy() ëŒ€ì…, frameì— getattr(data, 'frame',0)ì„ ëŒ€ì…
                s += f"{i}: " # s(total ì§€ì—­ í¬ê¸°)ì— str i ê°’ì„ ëŒ€ì… 
            else:
                p, im0, frame = path, im0s.copy(), getattr(dataset, "frame", 0) 
            
            # pì— pathê°’ì´ í• ë‹¹ë¨ webcam
            # im0 im0sì˜ ë³µì‚¬ë³¸ì´ í• ë‹¹ë¨. ì›ë³¸ ì´ë¯¸ì§€ë¥¼ í‘œí˜„ 
            # frame getattr(dataset, "frame", 0)ì—ì„œ ì–»ì€ ê°’ì´ í• ë‹¹ datasetì— 'frame'ì´ë¼ëŠ” ì†ì„±ì´ ìˆìœ¼ë©´ frameì— í• ë‹¹
            # ì „ë°˜ì ìœ¼ë¡œ ë£¨í”„ ë‚´ì—ì„œ ì¶”ê°€ ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìš”í•œ ë³€ìˆ˜ë¥¼ ì¤€ë¹„
            list_x1 = []
            list_num = []
            p = Path(p)  # to Path ê²½ë¡œ
            save_path = str(save_dir / p.name)  # im.jpg
            # p.nameì€ ì›ë³¸ íŒŒì¼ëª… save_dirì€ ê²½ë¡œ 
            txt_path = str(save_dir / "labels" / p.stem) + ("" if dataset.mode == "image" else f"_{frame}")  # im.txt ì‚¬ìš©í•˜ì§€ ì•ŠìŒ 
            
            # ë¼ë²¨ ì •ë³´(ê²½ê³„ìƒì ì¢Œí‘œ ë° í´ë˜ìŠ¤ ë¼ë²¨)ê°€ ì €ì¥ëœ ê²½ë¡œë¥¼ êµ¬ì„±
            # pì—ëŠ” ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ë¡œ
            # p.stem ê²½ë¡œì—ì„œ íŒŒì¼ì´ë¦„(í™•ì¥ì ì œì™¸)ì„ ì¶”ì¶œ
            # dataset.modeëŠ” ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ê²½ìš°ì— ì ‘ë¯¸ì‚¬(í”„ë ˆì„ ë²ˆí˜¸ ê¸°ì¤€)ê°€ ì¶”ê°€ 
            # save_dirì´ /results/ì´ê³ , p.stemì´ 'my_image'ì´ê³ , dataset.modeê°€ 'image'ì¸ ê²½ìš° txt_pathëŠ” "result/labels/my_images.txt"ê°€ ë¨.
            
            s += "%gx%g " % im.shape[2:] 
            # im.shape[2:] ì´ë¯¸ì§€ì˜ ë„ˆë¹„ì™€ ë†’ì´ì— í•´ë‹¹í•˜ëŠ” ëª¨ëŒ± íŠœí”Œì˜ ë§ˆì§€ë§‰ ë‘ ìš”ì†Œë¥¼ ì¶”ì¶œ 
            # ex ì´ë¯¸ì§€ í¬ê¸°ê°€ 640(ë„ˆë¹„) x 480(ë†’ì´)ì¸ ê²½ìš° 640x480ì„ í¬í•¨í•˜ë„ë¡ sì— ëŒ€ì… 
            
            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh torch.tensor(im0.shape)ì— ë†’ì´ ë„“ì´ ìƒ‰ì„ ê°€ì ¸ì™€ì„œ gnì— ëŒ€ì…
           
            # ì •ê·œí™” ì´ë“ ê³„ì‚°
            # im0.shape ì›ë³¸ ì´ë¯¸ì§€ì˜ ëª¨ì–‘ì„ íŠœí”Œë¡œ ë°˜í™˜ ì»¬ëŸ¬ì´ë¯¸ì§€ì˜ ê²½ìš° ì¼ë°˜ì ìœ¼ë¡œ
            # ë†’ì´, ë„ˆë¹„, ìƒ‰ìƒ ì±„ë„ìˆ˜(ex RGB)ì˜ 3ì°¨ì›
            # ì²« ë²ˆì§¸ ìš”ì†Œ(1)ì€ ì´ë¯¸ì§€ì˜ ë„ˆë¹„ì— í•´ë‹¹
            # ë‘ ë²ˆì§¸ ìš”ì†Œ(0)ì€ ì´ë¯¸ì§€ì˜ ë†’ì´ì— í•´ë‹¹
            # ì •ê·œí™”ë¥¼ ìœ„í•´ ì„¸ ë²ˆì¨°ì™€ ë„¤ ë²ˆì¨° ìš”ì†Œ(1ê³¼ 0)ì„ ë°˜ë³µ
            # ì •ê·œí™” gnì€ ê²°ê³¼ gn í…ì„œì˜ ì •ê·œí™”ë¥¼ ìœ„í•œ ì •ë ¬(ì´ë•Œ ì •ë ¬ì— ë„ˆë¹„ì™€ ë†’ì´ë¥¼ í¬í•¨)
            # ì¦‰ ê²½ê³„ ìƒì ì¢Œí‘œë¥¼ ëª¨ë¸ì˜ ì¶œë ¥ í¬ê¸°ì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì¡°ì •í•˜ëŠ”ë° ì‚¬ìš© 
            
            imc = im0.copy() if save_crop else im0  # for save_crop im0.copy()ì—ì„œ ì˜¨ ê°’ì„ crop() í•´ë¼
            # save_crop argsê°€ Trueì´ë©´ imcëŠ” ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬
            # save_crop Falseì´ë©´ imcëŠ” ì›ë³¸ ì´ë¯¸ì§€ì™€ ë™ì¼í•´ì„œ ë³µì‚¬ë¥¼ í•˜ì§€ ì•ŠìŒ 
           
            annotator = Annotator(im0, line_width=line_thickness, example=str(names)) # im0ì€ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆìŒ, line_width = line_thickness box ì„  êµµê¸°ëŠ” 1, ì¸ì‹ëœ name
            
            # ê²½ê³„ ìƒì ë ˆì´ë¸”ê³¼ ì‹œê°ì  ì£¼ì„ì„ ì´ë¯¸ì§€ì— ì¶”ê°€í•˜ê¸° ìœ„í•œ ì£¼ì„ ê°œì²´ë¥¼ ì´ˆê¸°í™”
            # im0 ì›ë³¸ ì´ë¯¸ì§€ ë°ì´í„°
            # line_widthëŠ” ê²½ê³„ ìƒì ë° ì£¼ì„ì„ ê·¸ë¦¬ëŠ”ë° ì‚¬ìš© (ì„ ì˜ ë‘ê»˜ë¥¼ ì§€ì •í•´ì„œ)
            # ex run/detect/expì— ì´ë¯¸ì§€ë¥¼ ë³´ë©´ person, dog ê¸€ì´ ì í˜€ ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŒ  
            
            count = 0 
            # ìœ„ì˜ ë‚´ìš©ì€ ì›¹ìº ì¸ì§€ ì•„ë‹ˆì§€ êµ¬ë¶„í•˜ê³  ê²½ë¡œ ê°€ì ¸ì˜¤ê³ , ì´ë¯¸ì§€ì˜ í¬ê¸° ì•Œì•„ë‚´ê³ , cropì„ í™œì„±í™”í•˜ê³ , ë°•ìŠ¤ ì„  êµµê¸° ì •í•˜ê³ ,
            # countì— 0ì„ ëŒ€ì… 
            
            if len(det): # detì´ ì¸ì‹ ì´ë¯¸ì§€ì˜ ë‚´ìš©ë“¤ì„ ê±°ì˜ í¬í•¨í•˜ê³  ìˆëŠ” ë³€ìˆ˜ 
                # Rescale boxes from img_size to im0 size
                global global_list_num 
                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round() # ì´ë¯¸ì§€ë¥¼ detì˜ returnë˜ì–´ì˜¤ëŠ” ê°’ì„ ì˜ë¼ë¼ 
                # im.shape[2:]ì˜ ê²½ìš° ì²˜ë¦¬ëœ ì´ë¯¸ì§€(im)ì˜ í¬ê¸°(í­ê³¼ ë†’ì´)ë¥¼ ì¶”ì¶œ. imì˜ ëª¨ì–‘ì€ (batch_size, ì±„ë„, ë†’ì´,ë„ˆë¹„)í˜•ì‹
                # det[:,:4] detì˜ ì²˜ìŒ 4ê°œ ì—´ì„ ì„ íƒ. ì´ëŸ¬í•œ ì—´ì€ ëª¨ë¸ì—ì„œ ì˜ˆì¸¡í•œ ê²½ê³„ ìƒì ì¢Œí‘œ(x_min.y_min,x_max,y_max)
                # im0.shapeì€ ì›ë³¸ ì´ë¯¸ì§€(im0)ì˜ ëª¨ì–‘ì„ ë‚˜íƒ€ë‚´ë©° ì¼ë°˜ì ìœ¼ë¡œ í˜•ì‹(ë†’ì´, ë„ˆë¹„, ì±„ë„)ì„ ê°–ëŠ”ë‹¤.
                # scale_coords() ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í¬ê¸°ì—ì„œ ì›ë˜ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ê²½ê³„ ìƒì ì¢Œí‘œì˜ í¬ê¸°ë¥¼ ì¡°ì •í•˜ê³  ê²½ê³„ ìƒìê°€ ì›ë³¸ ì´ë¯¸ì§€ì™€ ì˜¬ë°”ë¥´ê²Œ ì •ë ¬ë˜ë„ë¡ í•¨.
                # .round()ëŠ” ê²°ê³¼ ì¢Œí‘œì˜ ìœ íš¨í•œ í”½ì…€ ìœ„ì¹˜ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ì •ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼ 
                # ì¦‰ ì´ ì½”ë“œ ì¤„ì€ ì›ë³¸ ì´ë¯¸ì§€ì˜ í¬ê¸°ì™€ ì¼ì¹˜í•˜ë„ë¡ ê²½ê³„ ìƒì ì¢Œí‘œë¥¼ ì¡°ì •í•˜ì—¬ ì •í™•í•œ ì‹œê°í™” ë° ì£¼ì„ì„ ì²˜ë¦¬ 

                # Print results
                for c in det[:, 5].unique(): # í•´ë‹¹ ì—´ì— ìˆëŠ” ê³ ìœ  ê°’(class ë¼ë²¨)ë¥¼ ë°˜í™˜. ë¼ë²¨ì´ë€ ëª¨ë¸ì„ í†µê³¼ì‹œì¼œì„œ ë‚˜ì˜¨ ê°’ 
                    n = (det[:, 5] == c).sum()  # detections per class ê° ê³ ìœ  í´ë˜ìŠ¤ ë ˆì´ë¸”(c)ì— ëŒ€í•´ í•´ë‹¹ í´ë˜ìŠ¤ì™€ ê´€ë ¨ëœ íƒì§€ ìˆ˜ë¥¼ ê³„ì‚° 
                    s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string ê¸€ì”¨ë¥¼ ì…íˆëŠ” ê³¼ì •
                    # .sum()ì€ ë§ˆìŠ¤í¬ì— ìˆëŠ” True ê°’ì˜ ì´ ê°œìˆ˜ë¥¼ ê³„ì‚° 
                    # {n} í˜„ì¬ í´ë˜ìŠ¤ íƒì§€ ê°¯ìˆ˜
                    # {names[int(c)]} í´ë˜ìŠ¤ ì´ë¦„(ì •ìˆ˜ í´ë˜ìŠ¤ ë¼ë²¨ cë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë¦„ ëª©ë¡ì—ì„œ ê²€ìƒ‰)
                    # {'s' * (n > 1)} ê°ì§€ê°€ ì—¬ëŸ¬ ê°œ(ë‘˜ ì´ìƒ) ìˆëŠ” ê²½ìš° í´ë˜ìŠ¤ ì´ë¦„ì— 's'ë¥¼ ì¶”ê°€
                    # ì¦‰ ê²€ìƒ‰ëœ í´ë˜ìŠ¤ì— ëŒ€í•œ ì •ë³´ì™€ í•´ë‹¹ í´ë˜ìŠ¤ì˜ ê°œìˆ˜ë¥¼ ë¬¸ìì—´ sì— ì¶•ì 

                # Write results
                for *xyxy, conf, cls in reversed(det):
                    # xyxyëŠ” ê° ê°ì§€ì—ì„œ ê²½ê³„ ìƒì ì¢Œí‘œ(x_min, y_min, x_max, y_max)ë¥¼ ê°ì§€
                    # confëŠ” íƒì§€ì™€ ê´€ë ¨ëœ ì‹ ë¢°ë„ ì ìˆ˜
                    # clsëŠ” í´ë˜ìŠ¤ ë ˆì´ë¸” 
                    # reversed(det) ê°ì§€ë¥¼ ì—­ë°©í–¥ìœ¼ë¡œ ê°ì§€ ì¦‰ ìˆœì„œë¥¼ ë°˜ëŒ€ë¡œ ë°”ê¿ˆ 
                    # ë£¨í”„ê°€ ë§ˆì§€ë§‰(ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„)ë¶€í„° ì²« ë²ˆì§¸(ê°€ì¥ ë‚®ì€ ì‹ ë¢°ë„)ê¹Œì§€ íƒì§€ë¥¼ ì²˜ë¦¬í•œë‹¤ëŠ” ëœ» 
                    # íƒì§€ì— ëŒ€í•œ ê²½ê³„ ìƒì ì¢Œí‘œ, ì‹ ë¢°ë„ ì ìˆ˜ ë° í´ë˜ìŠ¤ ë ˆì´ë¸”ì— ì—­ìˆœìœ¼ë¡œ ì•¡ì„¸ìŠ¤
                    
                    c = int(cls)  # integer class
                    label = names[c] if hide_conf else f"{names[c]}"
                    confidence = float(conf)
                    confidence_str = f"{confidence:.2f}"

                    if save_csv:
                        write_to_csv(p.name, label, confidence_str)

                    if save_txt:  # Write to file
                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format
                        with open(f"{txt_path}.txt", "a") as f:
                            f.write(("%g " * len(line)).rstrip() % line + "\n")

                    if save_img or save_crop or view_img:  # Add bbox to image
                        c = int(cls)  # integer class
                        im_re_0 = annotator.result()
                        # x1 = int(xyxy[0].item())
                        # print("x1=",x1)
                        
                        label = None if hide_labels else (names[c] if hide_conf else f"{names[c]} {conf:.2f}")
                        
                        # save_img, save_crop ë˜ëŠ” view_imgì˜ ì¡°ê±´ or ì…‹ ì¤‘ í•˜ë‚˜ë¼ë„ ì°¸ì´ë©´ ë°‘ì˜ ë‚´ìš©ì„ ì‹¤í–‰
                        # ë³€ìˆ˜ cì—ëŠ” cls ì •ìˆ˜ ê°’ì´ í• ë‹¹
                        # ë³€ìˆ˜ ë¼ë²¨ì€ ë‹¤ìŒ ì¡°ê±´ì— ê²°ì •
                        # hide_labelsê°€ Trueì´ë©´ ë ˆì´ë¸”ì€ ì—†ìŒìœ¼ë¡œ ì„¤ì •
                        # hide_confê°€ Trueì´ë©´ labelì€ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ cì— í•´ë‹¹í•˜ëŠ” ì´ë¦„ìœ¼ë¡œ ì„¤ì •
                        # ë‘ ì¡°ê±´ì´ ëª¨ë‘ ì¶©ì¡±ë˜ì§€ ì•Šìœ¼ë©´ labelì—ëŠ” ì†Œìˆ˜ì  ì´í•˜ ë‘ìë¦¬ë¡œ í˜•ì‹í™”ëœ ì‹ ë¢°ë„ ê°’ê³¼ í´ë˜ìŠ¤ ì´ë¦„ì´ ëª¨ë‘ í¬í•¨   
                    
                        annotator.box_label(xyxy, label, color=colors(c, True))
                        nn = label
                       # print('nn',nn)
                        ny = nn.split()
                        if ny[0] == 'a1':
                            ny[0] = 'ê°€'
                        elif ny[0] == 'a2':
                            ny[0] = 'ë‚˜'
                        elif ny[0] == 'a3':
                            ny[0] = 'ë‹¤'
                        elif ny[0] == 'a4':
                            ny[0] = 'ë¼'
                        elif ny[0] == 'a5':
                            ny[0] = 'ë§ˆ'
                        

                        elif ny[0] == 'a6':
                            ny[0] = 'ê±°'
                        elif ny[0] == 'a7':
                            ny[0] = 'ë„ˆ'
                        elif ny[0] == 'a8':
                            ny[0] = 'ë”'
                        elif ny[0] == 'a9':
                            ny[0] = 'ëŸ¬'
                        elif ny[0] == 'a10':
                            ny[0] = 'ë¨¸'
                        elif ny[0] == 'a11':
                            ny[0] = 'ë²„'
                        elif ny[0] == 'a12':
                            ny[0] = 'ì„œ'
                        elif ny[0] == 'a13':
                            ny[0] = 'ì–´'
                        elif ny[0] == 'a14':
                            ny[0] = 'ì €'
                        

                        elif ny[0] == 'a15':
                            ny[0] = 'ê³ '
                        elif ny[0] == 'a16':
                            ny[0] = 'ë…¸'
                        elif ny[0] == 'a17':
                            ny[0] = 'ë„'
                        elif ny[0] == 'a18':
                            ny[0] = 'ë¡œ'
                        elif ny[0] == 'a19':
                            ny[0] = 'ëª¨'
                        elif ny[0] == 'a20':
                            ny[0] = 'ë³´'
                        elif ny[0] == 'a21':
                            ny[0] = 'ì†Œ'
                        elif ny[0] == 'a22':
                            ny[0] = 'ì˜¤'
                        elif ny[0] == 'a23':
                            ny[0] = 'ì¡°'
                      

                        elif ny[0] == 'a24':
                            ny[0] = 'êµ¬'
                        elif ny[0] == 'a25':
                            ny[0] = 'ëˆ„'
                        elif ny[0] == 'a26':
                            ny[0] = 'ë‘'
                        elif ny[0] == 'a27':
                            ny[0] = 'ë£¨'
                        elif ny[0] == 'a28':
                            ny[0] = 'ë¬´'
                        elif ny[0] == 'a29':
                            ny[0] = 'ë¶€'
                        elif ny[0] == 'a30':
                            ny[0] = 'ìˆ˜'
                        elif ny[0] == 'a31':
                            ny[0] = 'ìš°'
                        elif ny[0] == 'a32':
                            ny[0] = 'ì£¼'
                            
                        elif ny[0] == 'b1':
                            ny[0] = 'ì•„'
                        elif ny[0] == 'b2':
                            ny[0] = 'ë°”'
                        elif ny[0] == 'b3':
                            ny[0] = 'ì‚¬'
                        elif ny[0] == 'b4':
                            ny[0] = 'ì'
                        elif ny[0] == 'c1':
                            ny[0] = 'ë°°'
                        elif ny[0] == 'd1':
                            ny[0] = 'í•˜'
                        elif ny[0] == 'd2':
                            ny[0] = 'í—ˆ'
                        elif ny[0] == 'd3':
                            ny[0] = 'í˜¸'
                        x1 = int(xyxy[0].item())
                        # y1 = int(xyxy[1].item())
                        # x2 = int(xyxy[2].item())
                        # y1 = int(xyxy[3].item())
                        list_x1.append(x1)
                        list_num.append(ny[0])
                    if save_crop:
                        save_one_box(xyxy, imc, file=save_dir / "crops" / names[c] / f"{p.stem}.jpg", BGR=True)
            for k in range(len(list_x1)):
                    for j in range(len(list_x1) - 1):
                        if list_x1[j] > list_x1[j + 1]:  # bounding box ì¢Œí‘œë¥¼ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
                            list_x1[j], list_x1[j + 1] = list_x1[j + 1], list_x1[j]
                            list_num[j], list_num[j + 1] = list_num[j + 1], list_num[j]
            list_numm = "".join(list_num)
            list_num_len = len(list_numm)
                #print("list_num",list_num)   
                    
            if ((list_numm[0] == '0' or list_numm[0] == '1' or list_numm[0] == '2' or list_numm[0] == '3' or
                    list_numm[0] == '4' or list_numm[0] == '5' or list_numm[0] == '6' or list_numm[0] == '7' or
                    list_numm[0] == '8' or list_numm[0] == '9') and
                    (list_numm[1] == '0' or list_numm[1] == '1' or list_numm[1] == '2' or list_numm[1] == '3' or
                    list_numm[1] == '4' or list_numm[1] == '5' or list_numm[1] == '6' or list_numm[1] == '7' or
                    list_numm[1] == '8' or list_numm[1] == '9') and
                    (list_numm[2] == 'ê°€' or list_numm[2] == 'ë‚˜' or list_numm[2] == 'ë‹¤' or list_numm[2] == 'ë¼' or
                    list_numm[2] == 'ë§ˆ' or list_numm[2] == 'ë°”' or list_numm[2] == 'ì‚¬' or list_numm[2] == 'ì•„' or
                    list_numm[2] == 'ì' or list_numm[2] == 'í•˜' or list_numm[2] == 'ê±°' or list_numm[2] == 'ë„ˆ' or
                    list_numm[2] == 'ë”' or list_numm[2] == 'ëŸ¬' or list_numm[2] == 'ë¨¸' or list_numm[2] == 'ë²„' or
                    list_numm[2] == 'ì„œ' or list_numm[2] == 'ì–´' or list_numm[2] == 'ì €' or list_numm[2] == 'í—ˆ' or
                    list_numm[2] == 'ê³ ' or list_numm[2] == 'ë…¸' or list_numm[2] == 'ë„' or list_numm[2] == 'ë¡œ' or
                    list_numm[2] == 'ëª¨' or list_numm[2] == 'ë³´' or list_numm[2] == 'ì†Œ' or list_numm[2] == 'ì˜¤' or
                    list_numm[2] == 'ì¡°' or list_numm[2] == 'í˜¸' or list_numm[2] == 'êµ¬' or list_numm[2] == 'ëˆ„' or
                    list_numm[2] == 'ë‘' or list_numm[2] == 'ë£¨' or list_numm[2] == 'ë¬´' or list_numm[2] == 'ë¶€' or
                    list_numm[2] == 'ìˆ˜' or list_numm[2] == 'ìš°' or list_numm[2] == 'ì£¼') and
                    (list_numm[3] == '0' or list_numm[3] == '1' or list_numm[3] == '2' or list_numm[3] == '3' or
                    list_numm[3] == '4' or list_numm[3] == '5' or list_numm[3] == '6' or list_numm[3] == '7' or
                    list_numm[3] == '8' or list_numm[3] == '9') and
                    (list_numm[4] == '0' or list_numm[4] == '1' or list_numm[4] == '2' or list_numm[4] == '3' or
                    list_numm[4] == '4' or list_numm[4] == '5' or list_numm[4] == '6' or list_numm[4] == '7' or
                    list_numm[4] == '8' or list_numm[4] == '9') and
                    (list_numm[5] == '0' or list_numm[5] == '1' or list_numm[5] == '2' or list_numm[5] == '3' or
                    list_numm[5] == '4' or list_numm[5] == '5' or list_numm[5] == '6' or list_numm[5] == '7' or
                    list_numm[5] == '8' or list_numm[5] == '9') and
                    (list_numm[6] == '0' or list_numm[6] == '1' or list_numm[6] == '2' or list_numm[6] == '3' or
                    list_numm[6] == '4' or list_numm[6] == '5' or list_numm[6] == '6' or list_numm[6] == '7' or
                    list_numm[6] == '8' or list_numm[6] == '9') and
                    (list_num_len == 7 or list_num_len == 8 or list_num_len == 9)):
                    
                        global_list_num = list_numm
                #print("global4=", global_list_num)

            elif ((list_numm[0] == '0' or list_numm[0] == '1' or list_numm[0] == '2' or list_numm[0] == '3' or
                    list_numm[0] == '4' or list_numm[0] == '5' or list_numm[0] == '6' or list_numm[0] == '7' or
                    list_numm[0] == '8' or list_numm[0] == '9') and
                    (list_numm[1] == '0' or list_numm[1] == '1' or list_numm[1] == '2' or list_numm[1] == '3' or
                    list_numm[1] == '4' or list_numm[1] == '5' or list_numm[1] == '6' or list_numm[1] == '7' or
                    list_numm[1] == '8' or list_numm[1] == '9') and
                    (list_numm[2] == '0' or list_numm[2] == '1' or list_numm[2] == '2' or list_numm[2] == '3' or
                    list_numm[2] == '4' or list_numm[2] == '5' or list_numm[2] == '6' or list_numm[2] == '7' or
                    list_numm[2] == '8' or list_numm[2] == '9') and
                    (list_numm[3] == 'ê°€' or list_numm[3] == 'ë‚˜' or list_numm[3] == 'ë‹¤' or list_numm[3] == 'ë¼' or
                    list_numm[3] == 'ë§ˆ' or list_numm[3] == 'ë°”' or list_numm[3] == 'ì‚¬' or list_numm[3] == 'ì•„' or
                    list_numm[3] == 'ì' or list_numm[3] == 'í•˜' or list_numm[3] == 'ê±°' or list_numm[3] == 'ë„ˆ' or
                    list_numm[3] == 'ë”' or list_numm[3] == 'ëŸ¬' or list_numm[3] == 'ë¨¸' or list_numm[3] == 'ë²„' or
                    list_numm[3] == 'ì„œ' or list_numm[3] == 'ì–´' or list_numm[3] == 'ì €' or list_numm[3] == 'í—ˆ' or
                    list_numm[3] == 'ê³ ' or list_numm[3] == 'ë…¸' or list_numm[3] == 'ë„' or list_numm[3] == 'ë¡œ' or
                    list_numm[3] == 'ëª¨' or list_numm[3] == 'ë³´' or list_numm[3] == 'ì†Œ' or list_numm[3] == 'ì˜¤' or
                    list_numm[3] == 'ì¡°' or list_numm[3] == 'í˜¸' or list_numm[3] == 'êµ¬' or list_numm[3] == 'ëˆ„' or
                    list_numm[3] == 'ë‘' or list_numm[3] == 'ë£¨' or list_numm[3] == 'ë¬´' or list_numm[3] == 'ë¶€' or
                    list_numm[3] == 'ìˆ˜' or list_numm[3] == 'ìš°' or list_numm[3] == 'ì£¼') and
                    (list_numm[4] == '0' or list_numm[4] == '1' or list_numm[4] == '2' or list_numm[4] == '3' or
                    list_numm[4] == '4' or list_numm[4] == '5' or list_numm[4] == '6' or list_numm[4] == '7' or
                    list_numm[4] == '8' or list_numm[4] == '9') and
                    (list_numm[5] == '0' or list_numm[5] == '1' or list_numm[5] == '2' or list_numm[5] == '3' or
                    list_numm[5] == '4' or list_numm[5] == '5' or list_numm[5] == '6' or list_numm[5] == '7' or
                    list_numm[5] == '8' or list_numm[5] == '9') and
                    (list_numm[6] == '0' or list_numm[6] == '1' or list_numm[6] == '2' or list_numm[6] == '3' or
                    list_numm[6] == '4' or list_numm[6] == '5' or list_numm[6] == '6' or list_numm[6] == '7' or
                    list_numm[6] == '8' or list_numm[6] == '9') and
                    (list_numm[7] == '0' or list_numm[7] == '1' or list_numm[7] == '2' or list_numm[7] == '3' or
                    list_numm[7] == '4' or list_numm[7] == '5' or list_numm[7] == '6' or list_numm[7] == '7' or
                    list_numm[7] == '8' or list_numm[7] == '9') and
                    (list_num_len == 7 or list_num_len == 8 or list_num_len == 9)):
                        global_list_num = list_numm
            print("p.stem",p.stem)
            print("p.name", p.name)
            print("label", label)
            print("global_list",global_list_num)

            # Stream results
            im0 = annotator.result() # ì›ë˜ ì´ë¯¸ì§€(im0)ì˜ ê²½ê³„ ìƒìì™€ ë ˆì´ë¸”ì„ ì¶”ê°€í•˜ëŠ”ë° ì‚¬ìš©ëœ ì£¼ì„ ê°œì²´ë¥¼ í˜¸ì¶œ
            # ê²°ê³¼ëŠ” ì‹œê°ì  ì£¼ì„(ê²½ê³„ ìƒì ë° ë ˆì´ë¸”)ì´ ì ìš©ëœ ì´ë°
            # im0 ì£¼ì„ì´ ë‹¬ë¦° ì´ë¯¸ì§€ë¡œ ì—…ë°ì´íŠ¸ë˜ì–´ ì¶”ê°€ ì²˜ë¦¬ ë˜ëŠ” ì €ì¥ ì¤€ë¹„
            if view_img:
                if platform.system() == "Linux" and p not in windows:
                    windows.append(p)
                    cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # allow window resize (Linux)
                    cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])
                cv2.imshow(str(p), im0)
                cv2.waitKey(1)  # 1 millisecond

            # Save results (image with detections)
            if save_img:
                if dataset.mode == "image":
                    cv2.imwrite(save_path, im0)
                else:  # 'video' or 'stream'
                    if vid_path[i] != save_path:  # new video
                        vid_path[i] = save_path
                        if isinstance(vid_writer[i], cv2.VideoWriter):
                            vid_writer[i].release()  # release previous video writer
                        if vid_cap:  # video
                            fps = vid_cap.get(cv2.CAP_PROP_FPS)
                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                        else:  # stream
                            fps, w, h = 30, im0.shape[1], im0.shape[0]
                        save_path = str(Path(save_path).with_suffix(".mp4"))  # force *.mp4 suffix on results videos
                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*"mp4v"), fps, (w, h))
                    vid_writer[i].write(im0)

        # Print time (inference-only)
        LOGGER.info(f"{s}{'' if len(det) else '(no detections), '}{dt[1].dt * 1E3:.1f}ms")

    # Print results
    t = tuple(x.t / seen * 1e3 for x in dt)  # speeds per image
    LOGGER.info(f"Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}" % t)
    if save_txt or save_img:
        s = f"\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}" if save_txt else ""
        LOGGER.info(f"Results saved to {colorstr('bold', save_dir)}{s}")
    if update:
        strip_optimizer(weights[0])  # update model (to fix SourceChangeWarning)


def parse_opt():
    """Parses command-line arguments for YOLOv5 detection, setting inference options and model configurations."""
    parser = argparse.ArgumentParser()
    parser.add_argument("--weights", nargs="+", type=str, default=ROOT / "yolov5s.pt", help="model path or triton URL") # yolo ëª¨ë¸ ì„ ì •
    parser.add_argument("--source", type=str, default=ROOT / "data/images", help="file/dir/URL/glob/screen/0(webcam)") # í•™ìŠµ ë°ì´í„° read ê²½ë¡œ
    parser.add_argument("--data", type=str, default=ROOT / "data/coco128.yaml", help="(optional) dataset.yaml path") # class ê²½ë¡œ ë° íŒŒì¼ 
    parser.add_argument("--imgsz", "--img", "--img-size", nargs="+", type=int, default=[640], help="inference size h,w") # í•™ìŠµ ì‚¬ì´ì¦ˆ ì–¼ë§ˆë¡œ ì¤„ê±°ëƒ
    parser.add_argument("--conf-thres", type=float, default=0.5, help="confidence threshold") # ì¸ì‹ë¥  ì„¤ì •
    parser.add_argument("--iou-thres", type=float, default=0.5, help="NMS IoU threshold") # ì¸ì‹ë¥  ì„¤ì •
    parser.add_argument("--max-det", type=int, default=1000, help="maximum detections per image") # ì´ë¯¸ì§€ ëª‡ ì¥ê¹Œì§€
    parser.add_argument("--device", default="", help="cuda device, i.e. 0 or 0,1,2,3 or cpu") # cpu í˜¹ì€ gpu ì‚¬ìš©í• ì§€ ì„¤ì • 
    parser.add_argument("--view-img", action="store_true", help="show results") # ì´ë¯¸ì§€ view 
    parser.add_argument("--save-txt", action="store_true", help="save results to *.txt")
    parser.add_argument("--save-csv", action="store_true", help="save results in CSV format")
    parser.add_argument("--save-conf", action="store_true", help="save confidences in --save-txt labels")
    parser.add_argument("--save-crop", action="store_true", help="save cropped prediction boxes") # Crop box ì„¤ì • 
    parser.add_argument("--nosave", action="store_true", help="do not save images/videos") # video ê´€ë ¨
    parser.add_argument("--classes", nargs="+", type=int, help="filter by class: --classes 0, or --classes 0 2 3")
    parser.add_argument("--agnostic-nms", action="store_true", help="class-agnostic NMS")
    parser.add_argument("--augment", action="store_true", help="augmented inference")
    parser.add_argument("--visualize", action="store_true", help="visualize features")
    parser.add_argument("--update", action="store_true", help="update all models")
    parser.add_argument("--project", default=ROOT / "runs/detect", help="save results to project/name") # ì¸ì‹ ë°ì´í„° ê²°ê³¼ê°€ ì €ì¥ë˜ëŠ” ê³³
    parser.add_argument("--name", default="exp", help="save results to project/name")
    parser.add_argument("--exist-ok", action="store_true", help="existing project/name ok, do not increment")
    parser.add_argument("--line-thickness", default=1, type=int, help="bounding box thickness (pixels)") # box êµµê¸°
    parser.add_argument("--hide-labels", default=False, action="store_true", help="hide labels")
    parser.add_argument("--hide-conf", default=False, action="store_true", help="hide confidences")
    parser.add_argument("--half", action="store_true", help="use FP16 half-precision inference")
    parser.add_argument("--dnn", action="store_true", help="use OpenCV DNN for ONNX inference")
    parser.add_argument("--vid-stride", type=int, default=1, help="video frame-rate stride")
    opt = parser.parse_args()
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand
    print_args(vars(opt))
    return opt


def main(opt):
    """Executes YOLOv5 model inference with given options, checking requirements before running the model."""
    check_requirements(ROOT / "requirements.txt", exclude=("tensorboard", "thop"))
    run(**vars(opt))


if __name__ == "__main__":
    opt = parse_opt()
    main(opt)
